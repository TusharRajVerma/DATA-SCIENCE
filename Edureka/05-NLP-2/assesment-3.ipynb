{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Write a program to input three sentences from user and creates the corpusExample: Let’s say these 3 are your strings:S1=” India won the match”S2=” England won the cricket match”S3=” Australia won the final match”Then Corpus (list of union of all words from all strings) is: [India, England, Australia, won, the, match, cricket, final]Create a function named “MakeCorpus” which will take list of string as an input and will return a list having union of all words. Save this function in a python file named “Corpus”. This can be used for future applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "s1=\"India won the match\"\n",
    "s2=\"England won the cricket match\"\n",
    "s3=\"Australia won the final match\"\n",
    "s1=word_tokenize(s1)\n",
    "s2=word_tokenize(s2)\n",
    "s3=word_tokenize(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cricket', 'Australia', 'India', 'England', 'the', 'final', 'won', 'match']\n"
     ]
    }
   ],
   "source": [
    "def Union(lst1, lst2, lst3): \n",
    "    final_list = list(set().union(lst1, lst2, lst3)) \n",
    "    return final_list \n",
    "  \n",
    "\n",
    "print(Union(s1, s2, s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "li=[]\n",
    "li=s1+s2+s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeCorpus(lst):\n",
    "    final_list = list(set(lst) | set(lst))\n",
    "    return final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=MakeCorpus(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cricket', 'Australia', 'India', 'England', 'the', 'final', 'won', 'match']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Write a program to input three sentences from user and convert them into vectors.   \n",
    "## Use presence and absence of words to build the vectors.\n",
    "## Example: Let’s say these 3 are your strings:S1=” India won the match”S2=” England won the cricket match”S3=” Australia won the final match”\n",
    "## Then Corpus (list of union of all words from all strings) is: [India, England, Australia, won, the, match, cricket, final]\n",
    "## So, S1 will be  [1,0,0,1,1,1,0,0] S2 will be  [0,1,0,1,1,1,1,0]S3 will be  [0,0,1,1,1,1,0,1]Create a functionnamed “PresenceAbsenceVectorization”\n",
    "## which will take list of string as an input and will return a list of vectors. Save this function ina python file named “Vectorization”. This can be used for future applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "co1,co2,co3=0,0,0\n",
    "sv1,sv2,sv3=[],[],[]\n",
    "for i in f:\n",
    "    for j in s1:\n",
    "        if(i==j):\n",
    "            co1=1\n",
    "            sv1.append(co1)\n",
    "    if(co1==0):\n",
    "        sv1.append(co1)\n",
    "    co1=0\n",
    "    for j in s2:\n",
    "        if(i==j):\n",
    "            co2=1\n",
    "            sv2.append(co2)\n",
    "    if(co2==0):\n",
    "        sv2.append(co2)\n",
    "    co2=0\n",
    "    for j in s3:\n",
    "        if(i==j):\n",
    "            co3=1\n",
    "            sv3.append(co3)\n",
    "    if(co3==0):\n",
    "        sv3.append(co3)\n",
    "    co3=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Create a function named “CountVectorization” which will take list of string as an input and will return a list of vectors. Save this function in a python file named “Vectorization”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=\"A lives with B A plays with C\"\n",
    "s2=\"B lives with C B plays with D\"\n",
    "s3=\"C lives with D C plays with A\"\n",
    "s1=word_tokenize(s1)\n",
    "s2=word_tokenize(s2)\n",
    "s3=word_tokenize(s3)\n",
    "lis=Union(s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lic=[]\n",
    "def CountVectorization(li):\n",
    "        count=0\n",
    "        for i in lis:\n",
    "            for j in li:\n",
    "                if(i==j):\n",
    "                    count=count+1\n",
    "            lic.append(count)\n",
    "            count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorization(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'lives', 'with', 'B', 'A', 'plays', 'with', 'C']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 1, 0, 2]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. You can use already available python TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Corpus=s1+s2+s3\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def TFIDFVectorization(Corp):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(Corp)\n",
    "TFIDFVectorization(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
