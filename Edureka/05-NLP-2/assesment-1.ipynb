{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Write a program to enter a string from user and perform following tasks\n",
    "## Write a python functionnamed “Tokenize”which returnsthe tokenized string\n",
    "## Print tokens along with the frequency of each tokenusing the above function\n",
    "## Printthe 5 least occurring tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the stringhello world in this world you will study the world using python and country using python\n"
     ]
    }
   ],
   "source": [
    "msg=str(input('Enter the string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world in this world you will study the world using python and country using python'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of hello is : 1\n",
      "Frequency of world is : 3\n",
      "Frequency of in is : 1\n",
      "Frequency of this is : 1\n",
      "Frequency of you is : 1\n",
      "Frequency of will is : 1\n",
      "Frequency of study is : 1\n",
      "Frequency of the is : 1\n",
      "Frequency of using is : 2\n",
      "Frequency of python is : 2\n",
      "Frequency of and is : 1\n",
      "Frequency of country is : 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "dict={}\n",
    "def Tokenized(text):  \n",
    "    tok=word_tokenize(text)\n",
    "    str2 = [] \n",
    "    for i in tok:              \n",
    "        if i not in str2: \n",
    "            str2.append(i)  \n",
    "               \n",
    "    for i in range(0, len(str2)): \n",
    "        dict[str2[i]]=tok.count(str2[i])\n",
    "        print('Frequency of', str2[i], 'is :', tok.count(str2[i]))\n",
    "  \n",
    "Tokenized(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 1,\n",
       " 'in': 1,\n",
       " 'this': 1,\n",
       " 'you': 1,\n",
       " 'will': 1,\n",
       " 'study': 1,\n",
       " 'the': 1,\n",
       " 'and': 1,\n",
       " 'country': 1,\n",
       " 'using': 2,\n",
       " 'python': 2,\n",
       " 'world': 3}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortdict={k: v for k, v in sorted(dict.items(), key=lambda item: item[1])}\n",
    "sortdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "in\n",
      "this\n",
      "you\n",
      "will\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for k in sortdict:\n",
    "    if(i<5):\n",
    "        print(k)\n",
    "    else:\n",
    "        break\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Write a program to enter a string from user and perform following tasks.\n",
    "## •Write a python function named “RemoveStopWords”which returns the string after removing stop words\n",
    "## •Count frequency ofeach stop word present in a string using the above function\n",
    "## •Plot a bar graph depicting stop wordsand their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the stringHello in a this of a world that has a country and an end to the world\n"
     ]
    }
   ],
   "source": [
    "msg2=str(input('Enter the string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok=word_tokenize(msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def RemoveStopWords(text):\n",
    "    return [word for word in text.split() if word.lower() \n",
    "            not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=RemoveStopWords(msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', 'country', 'end', 'world']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'in',\n",
       " 'a',\n",
       " 'this',\n",
       " 'of',\n",
       " 'a',\n",
       " 'world',\n",
       " 'that',\n",
       " 'has',\n",
       " 'a',\n",
       " 'country',\n",
       " 'and',\n",
       " 'an',\n",
       " 'end',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword=[]\n",
    "cou=0\n",
    "for i in tok:\n",
    "    for j in stop:\n",
    "        if(j==i):\n",
    "            cou=1\n",
    "    if(cou==0):\n",
    "        stopword.append(i)\n",
    "    cou=0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'a', 'this', 'of', 'a', 'that', 'has', 'a', 'and', 'an', 'to', 'the']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of in is : 1\n",
      "Frequency of a is : 3\n",
      "Frequency of this is : 1\n",
      "Frequency of of is : 1\n",
      "Frequency of that is : 1\n",
      "Frequency of has is : 1\n",
      "Frequency of and is : 1\n",
      "Frequency of an is : 1\n",
      "Frequency of to is : 1\n",
      "Frequency of the is : 1\n"
     ]
    }
   ],
   "source": [
    "str2 = [] \n",
    "st=[]\n",
    "fr=[]\n",
    "for i in stopword:              \n",
    "        if i not in str2: \n",
    "            str2.append(i)  \n",
    "for i in range(0, len(str2)): \n",
    "        st.append(str2[i])\n",
    "        fr.append(tok.count(str2[i]))\n",
    "        print('Frequency of', str2[i], 'is :', tok.count(str2[i]))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopwords']=st\n",
    "df['frequency']=fr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopwords</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>has</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>an</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stopwords  frequency\n",
       "0        in          1\n",
       "1         a          3\n",
       "2      this          1\n",
       "3        of          1\n",
       "4      that          1\n",
       "5       has          1\n",
       "6       and          1\n",
       "7        an          1\n",
       "8        to          1\n",
       "9       the          1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(df['stopwords'],df['frequency'])\n",
    "plt.xlabel('stopwords')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Write a program to enter a string from user and perform following tasks\n",
    "## •Write a python functionnamed “Lemmatize”which returns a string after lemmatizing the string.\n",
    "## •Write a python functionnamed “Stemmed” which returns a string after stemming the string. (Use any stemmer of your preference)\n",
    "## •Print all the words along with their lemmatized and stemmed form using theabove functions \n",
    "##  •Save these results in a csv file having 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3='he corpora  better and pythons rocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok=word_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=[]\n",
    "def lemmatized(t):\n",
    "    for i in t:\n",
    "        le.append(lem.lemmatize(i))\n",
    "        print(lem.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "corpus\n",
      "better\n",
      "and\n",
      "python\n",
      "rock\n"
     ]
    }
   ],
   "source": [
    "lemmatized(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['Orignal Word']=tok\n",
    "dfa['Lemmatized Form']=le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orignal Word</th>\n",
       "      <th>Lemmatized Form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpora</td>\n",
       "      <td>corpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pythons</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rocks</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Orignal Word Lemmatized Form\n",
       "0           he              he\n",
       "1      corpora          corpus\n",
       "2       better          better\n",
       "3          and             and\n",
       "4      pythons          python\n",
       "5        rocks            rock"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "corpora\n",
      "better\n",
      "and\n",
      "python\n",
      "rock\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ste=[]\n",
    "ps=PorterStemmer()\n",
    "def stemmed(example_words):\n",
    "    for w in example_words:\n",
    "        ste.append(ps.stem(w))\n",
    "        print(ps.stem(w))\n",
    "stemmed(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['Stemmed Form']=ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orignal Word</th>\n",
       "      <th>Lemmatized Form</th>\n",
       "      <th>Stemmed Form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpora</td>\n",
       "      <td>corpus</td>\n",
       "      <td>corpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better</td>\n",
       "      <td>better</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pythons</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rocks</td>\n",
       "      <td>rock</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Orignal Word Lemmatized Form Stemmed Form\n",
       "0           he              he           he\n",
       "1      corpora          corpus      corpora\n",
       "2       better          better       better\n",
       "3          and             and          and\n",
       "4      pythons          python       python\n",
       "5        rocks            rock         rock"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.to_csv('file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .Create a python file named “PreProcess” and perform the following tasks.\n",
    "## •Copy the function “Tokenize” in this file from question \n",
    "## 1•Copy thefunction “RemoveStopWords” in this file from question 2•Copy the function “Lemmatize” in this file from question \n",
    "## 3Create a function named “Refine” which accepts a string and call the above \n",
    "# 3 functions in the same order i.e. first Tokenize then RemoveStopWords then Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenized(text):  \n",
    "    tok=word_tokenize(text)\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(text):\n",
    "    return [word for word in text.split() if word.lower() \n",
    "            not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatized(t):\n",
    "    for i in t:\n",
    "        return lem.lemmatize(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Refine(realtext):\n",
    "    to=Tokenized(realtext)\n",
    "    fo=RemoveStopWords(to)\n",
    "    zo=lemmatized(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
